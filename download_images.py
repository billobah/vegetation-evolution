# Import Libraries
import os
import json
import tarfile
import requests
import sys
from dotenv import load_dotenv
from authentication import authenticate
from api import M2M  # Importation de la classe M2M depuis le projet GitHub

# Charger les variables d'environnement depuis .env
load_dotenv()

# R√©cup√©rer l'API Key depuis le fichier .env
TOKEN_KEY = os.getenv('USGS_TOKEN')
USER_NAME = os.getenv("USGS_USERNAME")
SERVICE_URL = "https://m2m.cr.usgs.gov/api/api/json/stable/"
LOGIN_URL = SERVICE_URL + "login-token"

# API URLs
M2M_URL = "https://m2m.cr.usgs.gov/api/api/json/stable/"
SEARCH_URL = M2M_URL + "scene-search"
DOWNLOAD_URL = M2M_URL + "download-request"

api_key = authenticate(user_name=USER_NAME, token_value=TOKEN_KEY, login_url=LOGIN_URL)
HEADERS = {"X-Auth-Token": api_key}

# Fonction pour envoyer une requ√™te API
def send_request(url, payload):
    """Envoie une requ√™te API POST et retourne la r√©ponse JSON."""
    print(f"\nüîé Envoi de la requ√™te API √† {url}...")
    
    response = requests.post(url, json=payload, headers=HEADERS)

    if response.status_code != 200:
        print(f"‚ùå Erreur API ({url}) : {response.text}")
        return None

    try:
        data = response.json()
        return data
    except json.JSONDecodeError:
        print("‚ùå Erreur lors de la conversion JSON.")
        return None

# Recherche d'images Landsat
search_payload = {
    "datasetName": "LANDSAT_ETM_C2_L2",  
    "spatialFilter": {
        "filterType": "mbr",
        "lowerLeft": {"latitude": 8.5, "longitude": -9.5},
        "upperRight": {"latitude": 9.8, "longitude": -8.2}
    },
    "temporalFilter": {
        "startDate": "1999-07-23",
        "endDate": "2025-12-31"
    },
    "maxResults": 10,
    "cloudCoverFilter": {"max": 10, "min": 0},
}

results = send_request(SEARCH_URL, search_payload)

if not results or "data" not in results or "results" not in results["data"]:
    print("‚ùå Aucune donn√©e trouv√©e ou erreur API.")
    sys.exit()

scenes = results["data"]["results"]

if not isinstance(scenes, list):
    print(f"‚ùå Erreur : `scenes` devrait √™tre une liste mais est de type {type(scenes)}.")
    sys.exit()

print(f"‚úÖ {len(scenes)} sc√®nes trouv√©es.")

# Cr√©ation du dossier pour les t√©l√©chargements
output_dir = 'data/raw/landsat'
os.makedirs(output_dir, exist_ok=True)

# Fonction pour extraire uniquement les bandes B3 et B4
def extract_b3_b4(tar_path, dest_dir):
    """Extrait les bandes B3 (Rouge) et B4 (NIR) d'une archive TAR."""
    with tarfile.open(tar_path, 'r') as tar:
        members = tar.getmembers()
        b3_b4_members = [m for m in members if '_B3.TIF' in m.name or '_B4.TIF' in m.name]

        if b3_b4_members:
            tar.extractall(path=dest_dir, members=b3_b4_members)
            print(f"üìÇ Bandes B3 et B4 extraites dans : {dest_dir}")
        else:
            print(f"‚ö†Ô∏è Aucune bande B3 ou B4 trouv√©e dans : {tar_path}")

# T√©l√©chargement des images
for scene in scenes:
    if not isinstance(scene, dict):
        print(f"‚ùå Erreur : `scene` n'est pas un dictionnaire mais {type(scene)}")
        continue

    entity_id = scene.get('entityId')
    display_id = scene.get('displayId')

    # Extraction de la date au format YYYY-MM-DD
    acquisition_date = None
    if display_id and len(display_id) > 20:
        acquisition_date = display_id.split("_")[3]  
        acquisition_date = f"{acquisition_date[:4]}-{acquisition_date[4:6]}-{acquisition_date[6:]}"  

    if not acquisition_date or not entity_id:
        print("‚ö†Ô∏è Donn√©es de sc√®ne manquantes, passage √† la suivante.")
        continue

    print(f"\nüì• T√©l√©chargement de la sc√®ne : {entity_id} - Date : {acquisition_date}")

    # Cr√©ation d'un dossier par date
    date_dir = os.path.join(output_dir, acquisition_date)
    os.makedirs(date_dir, exist_ok=True)

    # Demande de t√©l√©chargement
    download_payload = {
        "downloads": [{"entityId": entity_id, "productId": entity_id, "datasetName": "landsat_etm_c2_l2"}]
    }
    download_results = send_request(DOWNLOAD_URL, download_payload)

    # V√©rification de la structure de r√©ponse
    if not download_results or "data" not in download_results:
        print(f"‚ö†Ô∏è Erreur lors de la demande de t√©l√©chargement pour la sc√®ne {entity_id}.")
        print(f"R√©ponse de l'API : {json.dumps(download_results, indent=2)}")
        continue

    if not isinstance(download_results["data"], list) or not download_results["data"]:
        print(f"‚ö†Ô∏è Aucune donn√©e de t√©l√©chargement disponible pour la sc√®ne {entity_id}.")
        continue

    # V√©rification que la cl√© "url" existe bien
    first_download = download_results["data"][0]
    if "url" not in first_download:
        print(f"‚ö†Ô∏è La cl√© 'url' est absente dans la r√©ponse de t√©l√©chargement pour {entity_id}.")
        print(f"R√©ponse API : {json.dumps(first_download, indent=2)}")
        continue

    download_url = first_download["url"]

    # T√©l√©chargement du fichier
    tar_path = os.path.join(date_dir, f"{entity_id}.tar")
    try:
        response = requests.get(download_url, stream=True)
        response.raise_for_status()
        with open(tar_path, "wb") as file:
            for chunk in response.iter_content(chunk_size=8192):
                file.write(chunk)

        print(f"‚úÖ T√©l√©chargement termin√© : {tar_path}")

        # Extraction des bandes B3 et B4
        extract_b3_b4(tar_path, date_dir)

    except requests.RequestException as e:
        print(f"‚ùå Erreur lors du t√©l√©chargement de {entity_id} : {e}")

print("\n‚úÖ T√©l√©chargements termin√©s et images organis√©es par date.")
